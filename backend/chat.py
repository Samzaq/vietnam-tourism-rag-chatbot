from ollama import chat
import os
from retriever import Retriever
from smooth_context import smooth_contexts
from data_loader import load_meta_corpus
from typing import List, Dict
from openai import OpenAI, AsyncOpenAI
from dotenv import load_dotenv
import chromadb
import pprint
import time

load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

CHROMA_DB_DIR = "data/chroma_db"
chroma_client = chromadb.PersistentClient(path=CHROMA_DB_DIR)
collection = chroma_client.get_collection(name="vietnam_tourism")

prompt_template = (
    """###YÃªu cáº§u: Báº¡n lÃ  má»™t trá»£ lÃ½ du lá»‹ch thÃ´ng minh, chuyÃªn cung cáº¥p cÃ¢u tráº£ lá»i dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c truy xuáº¥t tá»« há»‡ thá»‘ng vá» du lá»‹ch Viá»‡t Nam. Khi nháº­n Ä‘Æ°á»£c dá»¯ liá»‡u truy xuáº¥t tá»« RAG, hÃ£y:  

    1. PhÃ¢n tÃ­ch dá»¯ liá»‡u Ä‘á»ƒ tráº£ lá»i Ä‘Ãºng trá»ng tÃ¢m cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng. Chá»‰ tráº£ lá»i dá»±a trÃªn dá»¯ liá»‡u Ä‘Æ°á»£c cung cáº¥p, khÃ´ng suy Ä‘oÃ¡n hoáº·c táº¡o ra thÃ´ng tin má»›i.
    2. TÃ³m táº¯t thÃ´ng tin má»™t cÃ¡ch rÃµ rÃ ng, ngáº¯n gá»n nhÆ°ng váº«n Ä‘áº§y Ä‘á»§ Ã½ nghÄ©a.  
    3. Tráº£ lá»i vá»›i giá»ng Ä‘iá»‡u thÃ¢n thiá»‡n vÃ  dá»… tiáº¿p cáº­n.  
    4. Náº¿u dá»¯ liá»‡u truy xuáº¥t khÃ´ng cÃ³ thÃ´ng tin liÃªn quan Ä‘áº¿n cÃ¢u há»i hoáº·c khÃ´ng cÃ³ dá»¯ liá»‡u nÃ o Ä‘Æ°á»£c truy xuáº¥t, hÃ£y tráº£ lá»i: "Xin lá»—i, tÃ´i khÃ´ng cÃ³ thÃ´ng tin phÃ¹ há»£p Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i nÃ y."  
    5. Náº¿u cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n chá»§ Ä‘á» du lá»‹ch Viá»‡t Nam (out domain) hÃ£y giá»›i thiá»‡u lá»‹ch sá»± vá» lÄ©nh vá»±c cá»§a mÃ¬nh.
    6. Tráº£ lá»i cÃ¢u há»i báº±ng ngÃ´n ngá»¯: {language}

    ###Dá»±a vÃ o má»™t sá»‘ ngá»¯ cáº£nh truy xuáº¥t Ä‘Æ°á»£c dÆ°á»›i Ä‘Ã¢y náº¿u báº¡n tháº¥y nÃ³ cÃ³ liÃªn quan Ä‘áº¿n cÃ¢u há»i thÃ¬ tráº£ lá»i cÃ¢u há»i á»Ÿ cuá»‘i. {input}
    ###CÃ¢u há»i tá»« ngÆ°á»i dÃ¹ng: {question}
    ###Náº¿u tháº¥y ngá»¯ cáº£nh cÃ³ liÃªn quan Ä‘áº¿n cÃ¢u há»i hÃ£y tráº£ lá»i chi tiáº¿t vÃ  Ä‘áº§y Ä‘á»§ dá»±a trÃªn ngá»¯ cáº£nh."""
)

def get_prompt(question, contexts, language):
    # context = "\n\n".join([f"Context [{i+1}]: {x['passage']}" for i, x in enumerate(contexts)])
    context = "\n\n".join([f"Context [{i+1}]: {x}" for i, x in enumerate(contexts)])

    input = f"\n\n{context}\n\n"
    prompt = prompt_template.format(
        input=input,
        question=question, 
        language=language
    )
    return prompt


def classify_small_talk(input_sentence, language):
    prompt = f"""
    ###YÃªu cáº§u: Báº¡n lÃ  má»™t trá»£ lÃ½ há»¯u Ã­ch Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ phÃ¢n loáº¡i cÃ¡c cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng trong ngá»¯ cáº£nh cá»§a má»™t chatbot du lá»‹ch Viá»‡t Nam. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  xÃ¡c Ä‘á»‹nh liá»‡u cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng cÃ³ pháº£i lÃ  "small talk" hay khÃ´ng"
    ###"Small talk" Ä‘á» cáº­p Ä‘áº¿n nhá»¯ng chá»§ Ä‘á» trÃ² chuyá»‡n thÃ´ng thÆ°á»ng, khÃ´ng liÃªn quan trá»±c tiáº¿p Ä‘áº¿n du lá»‹ch Viá»‡t Nam, cháº³ng háº¡n nhÆ° chÃ o há»i, cÃ¢u há»i cÃ¡ nhÃ¢n, cÃ¢u chuyá»‡n cÆ°á»i.
    Náº¿u cÃ¢u há»i khÃ´ng pháº£i lÃ  small talk vÃ  liÃªn quan Ä‘áº¿n du lá»‹ch, áº©m thá»±c, Ä‘iá»ƒm Ä‘áº¿n, hoáº¡t Ä‘á»™ng, báº¡n PHáº¢I cÃ³ tá»« "no" trong cÃ¢u tráº£ lá»i vÃ  tráº£ vá» "no."
    Náº¿u cÃ¢u há»i lÃ  small talk: KhÃ´ng tráº£ lá»i cÃ¢u há»i mÃ  hÃ£y giá»›i thiá»‡u vá» chatbot tÆ° váº¥n du lá»‹ch Viá»‡t Nam má»™t cÃ¡ch ngáº¯n gá»n vá»›i giá»ng Ä‘iá»‡u cuá»‘n hÃºt báº±ng ngÃ´n ngá»¯: {language}.

    ###VÃ­ dá»¥:
    User query: "ChÃ o báº¡n, hÃ´m nay tháº¿ nÃ o?"
    Response: "Cáº£m Æ¡n báº¡n Ä‘Ã£ quan tÃ¢m! MÃ¬nh lÃ  chatbot tÆ° váº¥n du lá»‹ch Viá»‡t Nam, sáºµn sÃ ng há»— trá»£ báº¡n khÃ¡m phÃ¡ cÃ¡c Ä‘iá»ƒm Ä‘áº¿n tuyá»‡t Ä‘áº¹p, mÃ³n Äƒn háº¥p dáº«n vÃ  nhiá»u hoáº¡t Ä‘á»™ng thÃº vá»‹. HÃ£y há»i mÃ¬nh báº¥t cá»© Ä‘iá»u gÃ¬ liÃªn quan Ä‘áº¿n du lá»‹ch nhÃ©! ðŸ˜Š"
    User query: "á»ž Ä‘Ã³ cÃ³ mÃ³n gÃ¬ ngon?"
    Response: "no"
    User query: "Báº¡n cÃ³ thÃ­ch Ä‘i du lá»‹ch khÃ´ng?"
    Response: "MÃ¬nh lÃ  chatbot tÆ° váº¥n du lá»‹ch Viá»‡t Nam, luÃ´n sáºµn sÃ ng há»— trá»£ báº¡n khÃ¡m phÃ¡ cÃ¡c Ä‘iá»ƒm Ä‘áº¿n tuyá»‡t vá»i, áº©m thá»±c háº¥p dáº«n vÃ  cÃ¡c hoáº¡t Ä‘á»™ng thÃº vá»‹. HÃ£y há»i tÃ´i báº¥t ká»³ Ä‘iá»u gÃ¬ liÃªn quan Ä‘áº¿n du lá»‹ch nhÃ©! ðŸ˜Š"
    User query: "HÃ  Ná»™i cÃ³ mÃ³n Äƒn nÃ o ngon nháº¥t?"
    Response: "no"
    User query: "CÃ¡c Ä‘á»‹a Ä‘iá»ƒm du lá»‹ch ná»•i tiáº¿ng á»Ÿ Huáº¿ lÃ  gÃ¬?"
    Response: "no"
    User query: "Cáº£m Æ¡n báº¡n"
    Response: "Cáº£m Æ¡n báº¡n Ä‘Ã£ ghÃ© thÄƒm! MÃ¬nh lÃ  chatbot tÆ° váº¥n du lá»‹ch Viá»‡t Nam, luÃ´n sáºµn sÃ ng giÃºp báº¡n khÃ¡m phÃ¡ cÃ¡c Ä‘iá»ƒm Ä‘áº¿n tuyá»‡t vá»i, áº©m thá»±c phong phÃº vÃ  nhiá»u hoáº¡t Ä‘á»™ng thÃº vá»‹. HÃ£y há»i mÃ¬nh báº¥t cá»© Ä‘iá»u gÃ¬ liÃªn quan Ä‘áº¿n du lá»‹ch nhÃ©!"
    ###Dá»±a trÃªn cÃ¢u há»i tá»« ngÆ°á»i dÃ¹ng, hÃ£y thá»±c hiá»‡n Ä‘Ãºng yÃªu cáº§u. CÃ¢u há»i tá»« ngÆ°á»i dÃ¹ng: {input_sentence}"""

    completion = client.chat.completions.create(
      model="gpt-4o-mini",
      messages=[
        {"role": "user", "content": prompt}
      ]
    )
    answer = completion.choices[0].message.content
    return answer.strip().lower()

# ---- Chroma-based Retrieval ----
def chroma_retrieve(query, topk=5):
    results = collection.query(query_texts=[query], n_results=topk)
    return results["documents"][0] if results and "documents" in results else []

def create_new_prompt(prompt, chat_history, user_query, **kwargs):
  new_prompt = f"{prompt} lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n: {chat_history} cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: {user_query}"
  for key, value in kwargs.items():
    new_prompt += f" {key}: {value}"

  return new_prompt

def chatbot(conversation_history: List[Dict[str, str]], language: str):
    """
    Async generator that yields chunks of text as they are generated.
    """
    user_query = conversation_history[-1]['content']

    meta_corpus = load_meta_corpus(r"data/corpus_chunks.jsonl")

    # Detect small talk
    result = classify_small_talk(user_query, language)
    print("result classify small talk:", result)

    # If it's small talk
    if "no" not in result:
        yield result
        return

    # If not small talk
    prompt_refiner = """Dá»±a trÃªn lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n vÃ  cÃ¢u há»i má»›i nháº¥t cá»§a ngÆ°á»i dÃ¹ng, cÃ³ thá»ƒ tham chiáº¿u Ä‘áº¿n ngá»¯ cáº£nh trong lá»‹ch sá»­ trÃ² chuyá»‡n, 
#             hÃ£y táº¡o thÃ nh má»™t cÃ¢u há»i Ä‘á»™c láº­p cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c mÃ  khÃ´ng cáº§n lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n vÃ  khÃ´ng bá»‹ máº¥t Ä‘i ngá»¯ cáº£nh.
#             KHÃ”NG tráº£ lá»i cÃ¢u há»i, chá»‰ cáº§n Ä‘iá»u chá»‰nh láº¡i náº¿u cáº§n, náº¿u khÃ´ng thÃ¬ giá»¯ nguyÃªn.
#             Quan trá»ng vÃ  pháº£i giá»¯ Ä‘Æ°á»£c ngá»¯ cáº£nh cá»§a cuá»™c nÃ³i chuyá»‡n.
#             KhÃ´ng bá»‹ máº¥t Ä‘i ngá»¯ cáº£nh.
#             Náº¿u cÃ¢u há»i báº±ng tiáº¿ng Anh, sau khi tinh chá»‰nh, hÃ£y dá»‹ch cÃ¢u há»i Ä‘Ã³ sang tiáº¿ng Viá»‡t."""

    new_prompt = create_new_prompt(
        prompt=prompt_refiner,
        chat_history=conversation_history,
        user_query=user_query,
    )

    # Step 1: Generate refined question
    refine = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": new_prompt}],
    )

    answer = refine.choices[0].message.content.strip()
    print("CÃ¢u há»i má»›i:", answer)
    question = answer

    # Step 2: Retrieve context
    top_passages = chroma_retrieve(question, topk=10)
    print(f"Retrieved {len(top_passages)} passages from Chroma.")
    pprint.pprint(top_passages)

    prompt = get_prompt(question, top_passages, language)

    # Step 3: Stream from OpenAI
    stream = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        stream=True,
    )

    for chunk in stream:
        if len(chunk.choices) > 0:
            content = getattr(chunk.choices[0].delta, "content", None)
            if content:
                yield content
